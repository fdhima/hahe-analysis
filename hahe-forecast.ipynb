{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in ./venv/lib/python3.12/site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./venv/lib/python3.12/site-packages (from xgboost) (2.29.2)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from xgboost) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/kaggle/input/hahe-statistics-all-programmes/hahe_all_21_24.csv\")\n",
    "df = pd.read_csv(\"hahe_all_21_24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>institution</th>\n",
       "      <th>academic_year</th>\n",
       "      <th>program</th>\n",
       "      <th>established</th>\n",
       "      <th>graduate</th>\n",
       "      <th>registered</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens School of Fine Arts</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Fine Arts</td>\n",
       "      <td>03/07/1990</td>\n",
       "      <td>99</td>\n",
       "      <td>1570</td>\n",
       "      <td>140</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens School of Fine Arts</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Art Theory and History</td>\n",
       "      <td>07/09/2009</td>\n",
       "      <td>116</td>\n",
       "      <td>577</td>\n",
       "      <td>83</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aristotle University of Thessaloniki</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>English Language and Literature</td>\n",
       "      <td>03/05/1983</td>\n",
       "      <td>223</td>\n",
       "      <td>1557</td>\n",
       "      <td>227</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aristotle University of Thessaloniki</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Agricultural and Surveying Engineering</td>\n",
       "      <td>24/10/1962</td>\n",
       "      <td>75</td>\n",
       "      <td>937</td>\n",
       "      <td>125</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aristotle University of Thessaloniki</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Architectural Engineering</td>\n",
       "      <td>03/05/1983</td>\n",
       "      <td>142</td>\n",
       "      <td>1297</td>\n",
       "      <td>161</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            institution academic_year  \\\n",
       "0            Athens School of Fine Arts     2020-2021   \n",
       "1            Athens School of Fine Arts     2020-2021   \n",
       "2  Aristotle University of Thessaloniki     2020-2021   \n",
       "3  Aristotle University of Thessaloniki     2020-2021   \n",
       "4  Aristotle University of Thessaloniki     2020-2021   \n",
       "\n",
       "                                  program established  graduate  registered  \\\n",
       "0                               Fine Arts  03/07/1990        99        1570   \n",
       "1                  Art Theory and History  07/09/2009       116         577   \n",
       "2         English Language and Literature  03/05/1983       223        1557   \n",
       "3  Agricultural and Surveying Engineering  24/10/1962        75         937   \n",
       "4               Architectural Engineering  03/05/1983       142        1297   \n",
       "\n",
       "   enrolled  active  \n",
       "0       140     983  \n",
       "1        83     443  \n",
       "2       227     806  \n",
       "3       125     593  \n",
       "4       161     973  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"graduate\"\n",
    "\n",
    "features = [\"institution\", \"program\", \"registered\", \"enrolled\", \"active\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 27.62626598235188\n",
      "R²: 0.7511178082527201\n"
     ]
    }
   ],
   "source": [
    "df_rf = df.copy()\n",
    "\n",
    "train_df_rf = df_rf[df_rf[\"academic_year\"] != \"2023-2024\"]\n",
    "test_df_rf = df_rf[df_rf[\"academic_year\"] == \"2023-2024\"]\n",
    "\n",
    "X_train_rf = train_df_rf[features]\n",
    "y_train_rf = train_df_rf[target]\n",
    "\n",
    "X_test_rf = test_df_rf[features]\n",
    "y_test_rf = test_df_rf[target]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "categorical = [\"institution\", \"program\"]\n",
    "numerical = [\"registered\", \"enrolled\", \"active\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"num\", \"passthrough\", numerical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", model)])\n",
    "\n",
    "pipeline.fit(train_df_rf, y_train_rf)\n",
    "y_pred_rf = pipeline.predict(X_test_rf)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test_rf, y_pred_rf))\n",
    "print(\"R²:\", r2_score(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 26.35228157043457\n",
      "RMSE: 40.342270378560436\n",
      "R²: 0.773658812046051\n"
     ]
    }
   ],
   "source": [
    "df_xgb = df.copy()\n",
    "\n",
    "train_df_xgb = df_xgb[df_xgb[\"academic_year\"] != \"2023-2024\"]\n",
    "test_df_xgb = df_xgb[df_xgb[\"academic_year\"] == \"2023-2024\"]\n",
    "\n",
    "X_train_xgb = train_df_xgb[features]\n",
    "y_train_xgb = train_df_xgb[target]\n",
    "\n",
    "X_test_xgb = test_df_xgb[features]\n",
    "y_test_xgb = test_df_xgb[target]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"num\", \"passthrough\", numerical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([(\"preprocess\", preprocessor), (\"model\", xgb_model)])\n",
    "\n",
    "pipeline.fit(X_train_xgb, y_train_xgb)\n",
    "y_pred_xgb = pipeline.predict(X_test_xgb)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test_xgb, y_pred_xgb))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_xgb, y_pred_xgb)))\n",
    "print(\"R²:\", r2_score(y_test_xgb, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time aware model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  : 11.98\n",
      "RMSE : 15.47\n",
      "R²   : 0.968\n"
     ]
    }
   ],
   "source": [
    "df_time_aware = df.copy()\n",
    "df_time_aware = df_time_aware.sort_values(\n",
    "    by=[\"institution\", \"program\", \"academic_year\"]\n",
    ")\n",
    "\n",
    "df_time_aware[\"graduate_lag_1\"] = df_time_aware.groupby([\"institution\", \"program\"])[\n",
    "    \"graduate\"\n",
    "].shift(1)\n",
    "\n",
    "df_time_aware[\"graduate_lag_2\"] = df_time_aware.groupby([\"institution\", \"program\"])[\n",
    "    \"graduate\"\n",
    "].shift(2)\n",
    "\n",
    "df_time_aware[\"graduate_growth\"] = (\n",
    "    df_time_aware[\"graduate_lag_1\"] - df_time_aware[\"graduate_lag_2\"]\n",
    ") / df_time_aware[\"graduate_lag_2\"]\n",
    "\n",
    "df_time_aware = df_time_aware.replace([np.inf, -np.inf], np.nan)\n",
    "df_time_aware = df_time_aware.dropna().reset_index(\n",
    "    drop=True\n",
    ")  # Drop NaN values since they indicate no historical information\n",
    "\n",
    "train_df_time_aware = df_time_aware[df_time_aware[\"academic_year\"] != \"2023-224\"]\n",
    "test_df_time_aware = df_time_aware[df_time_aware[\"academic_year\"] == \"2023-2024\"]\n",
    "\n",
    "features_time_aware = [\n",
    "    \"institution\",\n",
    "    \"program\",\n",
    "    \"registered\",\n",
    "    \"enrolled\",\n",
    "    \"active\",\n",
    "    \"graduate_lag_1\",\n",
    "    \"graduate_lag_2\",\n",
    "    \"graduate_growth\",\n",
    "]\n",
    "\n",
    "\n",
    "X_train_time_aware = train_df_time_aware[features_time_aware]\n",
    "y_train_time_aware = train_df_time_aware[target]\n",
    "\n",
    "X_test_time_aware = test_df_time_aware[features_time_aware]\n",
    "y_test_time_aware = test_df_time_aware[target]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "categorical = [\"institution\", \"program\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"num\", \"passthrough\", numerical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([(\"preprocess\", preprocessor), (\"model\", xgb_model)])\n",
    "\n",
    "pipeline.fit(X_train_time_aware, y_train_time_aware)\n",
    "y_pred_time_aware = pipeline.predict(X_test_time_aware)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test_time_aware, y_pred_time_aware)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_time_aware, y_pred_time_aware))\n",
    "r2 = r2_score(y_test_time_aware, y_pred_time_aware)\n",
    "\n",
    "print(f\"MAE  : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 39.90413533834587\n",
      "Baseline R² : 0.4322106846281206\n"
     ]
    }
   ],
   "source": [
    "# Compare against a naive baseline\n",
    "baseline_pred = X_test_time_aware[\"graduate_lag_1\"]\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "print(\"Baseline MAE:\", mean_absolute_error(y_test_time_aware, baseline_pred))\n",
    "print(\"Baseline R² :\", r2_score(y_test_time_aware, baseline_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  MSE: 1933.20\n",
      "  R² : 0.731\n",
      "\n",
      "Ridge Regression:\n",
      "  MSE: 2897.99\n",
      "  R² : 0.597\n",
      "\n",
      "Lasso Regression:\n",
      "  MSE: 2046.16\n",
      "  R² : 0.715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Copy dataframe\n",
    "df_linear = df.copy()\n",
    "\n",
    "# Split data\n",
    "train_df_linear = df_linear[df_linear[\"academic_year\"] != \"2023-2024\"]\n",
    "test_df_linear = df_linear[df_linear[\"academic_year\"] == \"2023-2024\"]\n",
    "\n",
    "# Features and target\n",
    "features = [\"institution\", \"program\", \"enrolled\", \"registered\", \"active\"]\n",
    "target = \"graduate\"\n",
    "\n",
    "X_train_linear = train_df_linear[features]\n",
    "y_train_linear = train_df_linear[target]\n",
    "\n",
    "X_test_linear = test_df_linear[features]\n",
    "y_test_linear = test_df_linear[target]\n",
    "\n",
    "# Preprocessing\n",
    "categorical = [\"institution\", \"program\"]\n",
    "numerical = [\"enrolled\", \"registered\", \"active\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"num\", \"passthrough\", numerical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Linear Regression\n",
    "# -----------------------------\n",
    "linear_model = Pipeline(\n",
    "    [(\"preprocessing\", preprocessor), (\"regressor\", LinearRegression())]\n",
    ")\n",
    "\n",
    "linear_model.fit(X_train_linear, y_train_linear)\n",
    "y_pred_linear = linear_model.predict(X_test_linear)\n",
    "\n",
    "mse_linear = mean_squared_error(y_test_linear, y_pred_linear)\n",
    "r2_linear = r2_score(y_test_linear, y_pred_linear)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"  MSE: {mse_linear:.2f}\")\n",
    "print(f\"  R² : {r2_linear:.3f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Ridge Regression\n",
    "# -----------------------------\n",
    "ridge_model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"regressor\", Ridge(alpha=1.0)),  # alpha is regularization strength\n",
    "    ]\n",
    ")\n",
    "\n",
    "ridge_model.fit(X_train_linear, y_train_linear)\n",
    "y_pred_ridge = ridge_model.predict(X_test_linear)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test_linear, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test_linear, y_pred_ridge)\n",
    "\n",
    "print(\"Ridge Regression:\")\n",
    "print(f\"  MSE: {mse_ridge:.2f}\")\n",
    "print(f\"  R² : {r2_ridge:.3f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Lasso Regression\n",
    "# -----------------------------\n",
    "lasso_model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"regressor\", Lasso(alpha=0.1)),  # alpha is regularization strength\n",
    "    ]\n",
    ")\n",
    "\n",
    "lasso_model.fit(X_train_linear, y_train_linear)\n",
    "y_pred_lasso = lasso_model.predict(X_test_linear)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test_linear, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test_linear, y_pred_lasso)\n",
    "\n",
    "print(\"Lasso Regression:\")\n",
    "print(f\"  MSE: {mse_lasso:.2f}\")\n",
    "print(f\"  R² : {r2_lasso:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (SVR):\n",
      "  MSE: 4361.05\n",
      "  R² : 0.393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "df_svr = df.copy()\n",
    "\n",
    "train_df_svr = df_svr[df_svr[\"academic_year\"] != \"2023-2024\"]\n",
    "test_df_svr = df_svr[df_svr[\"academic_year\"] == \"2023-2024\"]\n",
    "\n",
    "features = [\"institution\", \"program\", \"enrolled\", \"registered\", \"active\"]\n",
    "target = \"graduate\"\n",
    "\n",
    "X_train_svr = train_df_svr[features]\n",
    "y_train_svr = train_df_svr[target]\n",
    "\n",
    "X_test_svr = test_df_svr[features]\n",
    "y_test_svr = test_df_svr[target]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"num\", StandardScaler(), numerical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "svr_model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"regressor\", SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "svr_model.fit(X_train_svr, y_train_svr)\n",
    "\n",
    "y_pred_svr = svr_model.predict(X_test_svr)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test_svr, y_pred_svr)\n",
    "r2_svr = r2_score(y_test_svr, y_pred_svr)\n",
    "\n",
    "print(\"Support Vector Regression (SVR):\")\n",
    "print(f\"  MSE: {mse_svr:.2f}\")\n",
    "print(f\"  R² : {r2_svr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['graduate_rate'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     51\u001b[39m     cat_maps[col] = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(df_nn[col].cat.categories))\n\u001b[32m     53\u001b[39m num_cols = [\u001b[33m\"\u001b[39m\u001b[33mregistered\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33menrolled\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mactive\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myears_since_established\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     54\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mgraduate_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgraduate_lag_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgraduate_lag_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgraduate_growth\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m X_num = \u001b[43mdf_nn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[43m]\u001b[49m.values\n\u001b[32m     56\u001b[39m scaler = StandardScaler()\n\u001b[32m     57\u001b[39m X_num_scaled = scaler.fit_transform(X_num)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/hahe-analysis/venv/lib/python3.12/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/hahe-analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/hahe-analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['graduate_rate'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "df_nn = df.copy()\n",
    "\n",
    "df_nn[\"established\"] = pd.to_datetime(df_nn[\"established\"], dayfirst=True)\n",
    "df_nn[\"years_since_established\"] = (\n",
    "    df_nn[\"academic_year\"].str[:4].astype(int) - df_nn[\"established\"].dt.year\n",
    ")\n",
    "\n",
    "# It causes overfitting, models uses the same variable as the target itself, in order to predict the target.\n",
    "# df_nn[\"graduate_rate\"] = df_nn[\"graduate\"] / df_nn[\"enrolled\"]\n",
    "\n",
    "df_nn[\"graduate_lag_1\"] = df_nn.groupby([\"institution\", \"program\"])[\n",
    "    \"graduate\"\n",
    "].shift(1)\n",
    "\n",
    "df_nn[\"graduate_lag_2\"] = df_nn.groupby([\"institution\", \"program\"])[\n",
    "    \"graduate\"\n",
    "].shift(2)\n",
    "\n",
    "df_nn[\"graduate_growth\"] = (\n",
    "    df_nn[\"graduate_lag_1\"] - df_nn[\"graduate_lag_2\"]\n",
    ") / df_nn[\"graduate_lag_2\"]\n",
    "\n",
    "df_nn = df_nn.replace([np.inf, -np.inf], np.nan)\n",
    "df_nn = df_nn.dropna().reset_index(\n",
    "    drop=True\n",
    ")  # Drop NaN values since they indicate no historical information\n",
    "\n",
    "# Fill missing values if any\n",
    "# df_nn.fillna(0, inplace=True)\n",
    "\n",
    "cat_cols = [\"institution\", \"program\", \"academic_year\"]\n",
    "cat_maps = {}\n",
    "for col in cat_cols:\n",
    "    df_nn[col] = df_nn[col].astype(\"category\")\n",
    "    df_nn[col + \"_id\"] = df_nn[col].cat.codes\n",
    "    cat_maps[col] = dict(enumerate(df_nn[col].cat.categories))\n",
    "\n",
    "num_cols = [\"registered\", \"enrolled\", \"active\", \"years_since_established\",\n",
    "            \"graduate_lag_1\", \"graduate_lag_2\", \"graduate_growth\"]\n",
    "X_num = df_nn[num_cols].values\n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "# Target\n",
    "y = df_nn[\"graduate\"].values\n",
    "\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(\n",
    "    X_num_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "cat_ids = [df_nn[col + \"_id\"].values for col in cat_cols]\n",
    "idx_train, idx_test = train_test_split(\n",
    "    np.arange(len(df_nn)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_num = X_num_scaled[idx_train]\n",
    "X_test_num = X_num_scaled[idx_test]\n",
    "\n",
    "X_train_cat = [df_nn[col + \"_id\"].values[idx_train] for col in cat_cols]\n",
    "X_test_cat = [df_nn[col + \"_id\"].values[idx_test] for col in cat_cols]\n",
    "\n",
    "y_train = y[idx_train]\n",
    "y_test = y[idx_test]\n",
    "\n",
    "embedding_sizes = {\n",
    "    \"institution\": min(50, len(cat_maps[\"institution\"]) // 2 + 1),\n",
    "    \"program\": min(50, len(cat_maps[\"program\"]) // 2 + 1),\n",
    "    \"academic_year\": min(10, len(cat_maps[\"academic_year\"]) // 2 + 1),\n",
    "}\n",
    "\n",
    "inputs_cat = []\n",
    "embeddings = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    n_unique = len(cat_maps[col])\n",
    "    emb_size = embedding_sizes[col]\n",
    "    inp = Input(shape=(1,), name=col)\n",
    "    emb = Embedding(input_dim=n_unique, output_dim=emb_size)(inp)\n",
    "    emb = Flatten()(emb)\n",
    "    inputs_cat.append(inp)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "input_num = Input(shape=(X_num_scaled.shape[1],), name=\"numeric_input\")\n",
    "\n",
    "x = Concatenate()(embeddings + [input_num])\n",
    "# x = Dense(128, activation=\"relu\")(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "output = Dense(1)(x)  # regression output\n",
    "\n",
    "model = Model(inputs=inputs_cat + [input_num], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_cat + [X_train_num],\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "\n",
    "loss, mae = model.evaluate(X_test_cat + [X_test_num], y_test)\n",
    "print(\"Test MAE:\", mae)\n",
    "\n",
    "y_pred = model.predict(X_test_cat + [X_test_num])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual graduates\")\n",
    "plt.ylabel(\"Predicted graduates\")\n",
    "plt.title(\"Actual vs Predicted Graduates\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test_cat + [X_test_num]).squeeze()\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "print(f\"Median AE: {medae:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8712772,
     "sourceId": 14022250,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
